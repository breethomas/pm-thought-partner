# Organizational AI Adoption: The CODER Framework

**Category:** AI-Era Practices
**Source:** Brian Balfour / Reforge
**Last Updated:** January 2025

## Overview

Most companies are lying to themselves about AI transformation. It's easy to write a memo declaring "we're AI-first," but talk doesn't change behavior. The gap between aspiration and reality is enormous.

**The truth:** AI transformation isn't blocked by technology—it's blocked by organizational friction. You need a systematic approach to drive real change, not just inspiring manifestos.

The **CODER Framework** provides that system: **Constraints, Ownership, Directives, Expectations, and Rewards**. It transforms organizational chaos into structured change.

## The Two Types of AI Value

Before diving into the framework, understand what you're actually trying to achieve.

### Value Capture: Just a Starting Point

**Definition:** Using AI to make existing work 10-15% more efficient.

**Examples:**
- Customer support chatbots handling 70% of tickets
- AI code reviews catching bugs before deployment
- Automated content generation for marketing
- Expense report processing

**Why companies love it:**
- Easy to measure ROI
- Quick to implement
- Low risk
- Doesn't require fundamental workflow changes

**The problem:** Value capture is defensive. Your competitors can implement the same efficiency gains. You're all running faster to stay in the same place.

**The ceiling is low.** You're competing on cost, not differentiation.

### Value Creation: The Competitive Moat

**Definition:** Using AI to deliver entirely new capabilities that were previously impossible or prohibitively expensive.

**Box CEO Aaron Levie's framing:**
> "In most businesses there's a near infinite backlog of this kind of work if you just start to ask the question of 'what if X thing was all of a sudden 100x cheaper or more accessible, what more could you do?'"

**Examples:**

**Duolingo:**
- Doubled language courses in one year
- AI grades difficulty for individual users in real-time
- Adjusts lessons dynamically based on user struggle/success
- CEO Luis von Ahn: "Being AI-first means we will need to rethink much of how we work. Making minor tweaks to systems designed for humans won't get us there."

**HubSpot:**
- AI-powered marketing insights analyze patterns across thousands of companies
- Provides personalized recommendations impossible with manual analysis
- Comprehensive customer view across marketing, sales, support
- SVP Nicholas Holland: "Software as a service is turning into results as a service"

**Notion:**
- AI workspace synthesizes information across entire knowledge base
- Fundamentally changes team collaboration patterns
- Integrated workflows, not point solutions

**How to identify value creation opportunities:**

**Start with "too hard" problems:**
- What features do you tell customers "we can't build" due to resource constraints?
- What requests get deprioritized because they're too time-intensive?
- What would you offer with unlimited developer hours?

**Look for "impossible economics":**
- What services require too much human involvement to scale?
- What personalizations are too expensive to deliver?
- What insights take too long to generate to be actionable?

**The goal:** Value capture is table stakes. Value creation is competitive advantage.

## The Five Barriers to AI Adoption

Your AI adoption moves at the speed of the weakest part of your system. Here are the barriers that consistently block transformation:

### 1. Political Barriers: When Roles Collide

**The problem:** AI gives everyone superpowers, but your org chart was designed for the pre-AI world.

**What's happening:**
- Engineers can now prototype UX flows
- Designers can write functional code
- PMs can create production-ready designs

**This creates political chaos:**

Traditional role boundaries are dissolving, but political structures built around those boundaries remain. People want to experiment but fear:
- Stepping on toes
- Being seen as overstepping their role
- "Tattling" on peers when they hit red tape

**Result:** Teams drop projects rather than navigate political friction.

**Signal you have this barrier:**
- Teams excited about AI capabilities but hesitant to use them
- Unclear boundaries about who can do what
- Projects stalling due to role confusion

### 2. Retrofitting: The Incremental Trap

**The problem:** Companies ask "How can we make existing processes 10% better?" instead of "How can we rethink this from scratch?"

**What retrofitting looks like:**
- Layering AI onto existing workflows
- Saving 30 minutes on a 3-hour task
- Incremental gains, not transformation

**Why it feels safe:**
- Logical and measurable
- Delivers some ROI
- Provides AI exposure to team

**Why it's a trap:**
- Only delivers incremental benefits
- Misses opportunity to reimagine the work
- In some cases, you could eliminate the task entirely

**This is why CIOs question AI ROI:** They're taking on AI tool costs but only measuring incremental improvements, not transformational benefits.

**Signal you have this barrier:**
- Team using AI to do existing work faster
- Not seeing breakthrough improvements
- No entirely new capabilities emerging

### 3. Procurement Barriers: When Defense Controls Offense

**The problem:** Legal, IT, and finance teams play defense (their job), but when defense controls the pace of change, you don't score points.

**What this looks like:**
- Legal taking weeks/months to review AI tool agreements
- IT creating endless security checkboxes for low-risk experimentation
- Finance applying "cut all SaaS spending" mentality to AI transformation

**The deeper issue:**
These teams are removed from understanding AI's potential impact. They focus on risk mitigation without weighing the opportunity cost of moving slowly.

**Livestorm CEO Gilles Bertaux's approach:**
> "Do the heavy lifting upfront (data sources, templates, prebuilt agents) so others can just build. The technical setup is handled by Data Ops and myself, but agent building should not be officially assigned to a single team to avoid bottlenecks and ensure broader team learning."

**Signal you have this barrier:**
- Most innovative people frustrated by procurement timelines
- Teams working around official processes
- People who want AI but aren't leading won't bother due to friction

### 4. Knowledge Barriers: Surface Learning Isn't Enough

**The problem:** Reading newsletters and listening to podcasts won't drive organizational transformation.

**What doesn't work:**
- Allocating small professional development budget
- Sharing resources and expecting people to "figure it out"
- Treating AI like any other skill development

**What's needed:**
- Hands-on experience with tools
- Frameworks for thinking about problems differently
- Time to develop new mental models
- Coordinated, deeper learning

**Signal you have this barrier:**
- People know AI is important and can speak the language
- They're not sure how to change day-to-day work
- Surface-level understanding without application

### 5. Permission Barriers: The Fear of Doing Something Wrong

**The most common sentiment:**
> "I don't know if I have permission to do this, and I just don't want to do anything wrong."

**The problem:** Smart, capable people paralyzed by uncertainty about what they're allowed to experiment with.

**What this looks like:**
- Seeing AI's potential but not knowing the boundaries
- Asking lots of questions about permission
- Worse: Not experimenting at all due to fear of crossing invisible lines

**The solution isn't unlimited permission** — it's crystal clear communication about boundaries.

**Some companies segment employees:**
- Different groups get different access levels
- Build confidence and governance gradually
- Clear communication about what each group can/can't do

**Signal you have this barrier:**
- People asking many questions about permission
- Little to no experimentation happening
- Fear of doing something wrong blocking action

**Key insight:** Most organizations struggle with multiple barriers simultaneously. Identify your primary bottleneck before trying to fix everything.

## The CODER Framework

Good code transforms inputs into predictable outputs through systematic steps. The CODER Framework does the same for AI adoption—it takes organizational chaos and creates structured change through five essential elements.

### Overview of the Framework

```
C - Constraints
O - Ownership
D - Directives
E - Expectations
R - Rewards
```

Each element addresses transformation at different organizational levels. You're not hoping people will change—you're creating systems that make change inevitable.

### 1. Constraints: The Most Important Element

**Core insight:** Constraints make the new behavior easier than the old behavior. Instead of AI adoption being "extra work," it becomes the natural path forward.

**The psychology:** Behavior change is hard and scary. Under pressure, people default to familiar approaches. Effective constraints remove the option to fall back.

**Example from a leading AI company:**
They benchmark team sizes against other companies with similar revenue, then cap internal teams at **1/5 the benchmark**. This forced their finance team to learn SQL instead of requesting more analysts.

#### Four Types of Constraints

**1. Time Constraints**
- Hackathons (1 hour, 1 day, 1 week)
- Dedicated AI exploration time
- "AI Fridays" for experimentation

**Example - Zapier:**
Paused all work for an entire week for a company-wide AI hackathon. CEO Wade Foster insisted on "Full-company participation."

> "We wanted everyone in the company regardless of technical capability to get a tactile feel for what was changing. For engineering that might be building AI features. For non-technical teams that might mean adopting AI products in your day to day tasks. The message was 'Everyone, let's get hands on keyboards. Build something real to develop a sense of what is possible with AI. Learn together.'"

**Result:** "Usage surged. But more importantly, the AI builder mentality stuck."

**2. Resource Constraints**
- Limit team sizes to force AI leverage
- Cap budgets to require efficiency
- Restrict headcount growth

**Why it works:** Forces teams to find AI solutions instead of throwing more people at problems.

**3. Process Constraints**
- "I will only review work that demonstrates AI augmentation"
- "All project phases must include AI prototyping before design reviews"
- "No feature ships without AI-assisted testing"

**Particularly effective example:**
A CEO announced: "I will only review work that demonstrates AI augmentation. If you can't show me how AI made your output better, faster, or more creative, we'll reschedule until you can."

**Result:** Forced every team to integrate AI into workflows—not as experiment, but as requirement for leadership engagement.

**4. Tool Constraints**
- Standardize on specific AI tools
- Require tool usage for certain workflows
- Remove legacy tools that don't integrate with AI

**Why constraints are #1:**
They create forcing functions. Without constraints, people revert to old behaviors under pressure.

### 2. Ownership: Someone Has to Drive the Bus

**The problem:** You can't declare "we are AI-first" and expect change to happen.

**The solution:** Someone needs to be the primary driver—making decisions, removing obstacles, and being accountable for transformation.

**Where ownership typically lives:**

**CEO/Founder level:**
- Cultural shifts this significant require authority only senior leadership possesses
- Not because they need to be AI experts
- Because changing how entire organizations work requires top-level power

**Example - Shopify:**
CEO Tobi Lütke took personal ownership. When teams hit procurement barriers or role confusion, they had clear escalation paths and decision-making authority.

**But ownership can't stop at the top.**

**Each functional leader owns their domain:**
- **CPO:** How product teams integrate AI into development workflows
- **CTO:** Engineering adoption and technical infrastructure
- **CMO:** Marketing's transition to AI-assisted content creation

**Alternative structure: VP of AI**

Some companies create a dedicated role to coordinate across functions. This person acts as a bridge between:
- Teams that want to adopt AI
- Defensive functions (legal, IT, finance) that need to evaluate risk

**Value:** Instead of five different PMs trying to work through procurement individually, you have single point of coordination.

**Key principle:** Ownership must be explicit, empowered, and accountable.

### 3. Directives: Turn Inspiration Into Specific Action

**The gap:** Expectations set the bar. Directives tell people exactly what to do.

**The goal:** Move from "what good looks like" to "here's your next step."

**The sweet spot:** 2-3 specific directives per functional team.
- Too few → People confused about where to start
- Too many → Overwhelm and analysis paralysis

**Effective directives are immediately actionable.**

People should be able to start implementing right after hearing them, without waiting for additional resources or approval.

#### Examples of Strong Directives

**Product Development:**
- "All project phases must include AI prototyping before design reviews"
- "User story creation requires AI-assisted persona validation"

**Sales:**
- "CRM updates must use AI transcription and summary tools for all customer calls"
- "Competitive intelligence reports require AI analysis of publicly available data"

**Customer Success:**
- "Support ticket resolution must attempt AI-assisted solutions before escalation"
- "Customer health scoring must incorporate AI analysis of usage patterns and communication sentiment"

**Engineering:**
- "All code reviews must include AI-assisted security and performance analysis"
- "Pull requests require AI-generated test coverage suggestions"

**Marketing:**
- "Campaign briefs require three AI-generated creative concepts before external agency work begins"
- "All content must show AI-assisted research and ideation in drafts"

**Notice:** These don't just say "use AI"—they specify exactly when and how AI should be integrated into existing workflows.

### 4. Expectations: Make the Abstract Concrete

**The purpose:** Translate high-level vision into specific, observable behaviors.

**Good expectations have three characteristics:**

**1. Specificity**
- Bad: "Use AI effectively"
- Good: "Every product feature must include at least one AI-generated prototype in the review process"

**2. Universality**
- Make it clear expectations apply to everyone
- As one CEO put it: "Everyone means everyone. Nobody gets to opt out because they're 'not technical' or 'too senior.'"

**3. Measurability**
- People should be able to assess whether they're meeting expectations without subjective interpretation

#### Function-Specific Expectations

**Product teams:**
"All user research synthesis must use AI analysis tools before presenting findings"

**Engineering teams:**
"Code reviews must include AI-assisted security and performance analysis"

**Marketing teams:**
"Campaign briefs require three AI-generated creative concepts before external agency work begins"

**Design teams:**
"All design explorations include AI-generated variations before final review"

**The goal:** Give people clear starting points when they ask, "What does AI adoption mean for my role?"

### 5. Rewards: Make It Matter for Careers

**Core insight:** People change behavior when change affects career progression.

**The problem:** Without accountability mechanisms, even best intentions fade when deadlines get tight.

**The solution:** Build accountability into existing performance management systems.

#### Three Integration Points

**1. Performance Reviews**
- AI adoption becomes part of formal review processes
- Not an add-on, but integrated into core job performance evaluation

**2. Leveling Guides**
- Update role progression requirements to include AI competency
- People can't advance to senior levels without demonstrating AI usage

**Example from a startup:**
Restructured engineering career ladder to include "AI-assisted development" as core competency. Engineers couldn't reach senior levels without showing proficiency in:
- Code generation
- Automated testing
- AI-enhanced debugging

**3. Promotion Criteria**
- Make AI adoption a factor in promotion decisions
- Creates clear career incentives for people who might see AI as "extra work"

#### Zapier's AI Fluency Framework

Zapier measures AI fluency by role along a spectrum of adoption:

**Levels:**
1. **Aware:** Understands AI exists, basic concepts
2. **Exploratory:** Experimenting with tools, learning
3. **Proficient:** Regular usage, integrated into workflows
4. **Advanced:** Teaching others, pushing boundaries
5. **Expert:** Driving innovation, creating new applications

**By role:**
- Different roles have different expected fluency levels
- Clear progression path within each role
- Helps team understand expectations and up-skilling path

**Why this works:** Aligns personal career growth with organizational AI adoption. People stop seeing AI as "something I should do" and start seeing it as "something I must do to advance."

## The Three Types of AI Adopters

Not everyone embraces change at the same pace. Understanding these groups is critical because they require completely different approaches.

**Typical distribution in most organizations:**
- 15-20% Catalysts
- 60-70% Converts
- 15-20% Anchors

**Your transformation success depends on converting the middle group while managing the extremes.**

### Catalysts: Your Early Adopters (15-20%)

**Who they are:**
- Already experimenting with AI tools on personal accounts
- Finding ways around rules because they understand staying current is non-negotiable
- Deeply curious and intrinsically motivated
- Sign up for courses on their own time
- Fight to get AI tools expensed
- Constantly share learnings with teammates

**What catalysts need from you:**
- ✅ Get out of their way
- ✅ Remove friction and barriers
- ✅ Give them bigger, more challenging problems
- ✅ Amplify their successes to other teams

**What NOT to do:**
- ❌ Assume everyone is a catalyst
- ❌ Expect everyone to self-motivate like they do
- ❌ Rely only on this group for transformation

**Key insight:** Founders and executives tend to be catalysts by nature. But you can't expect that from an entire team. Only ~15-20% will adapt based on enthusiasm alone.

### Converts: The Willing Majority (60-70%)

**Who they are:**
- Willing to adopt AI, but need support, structure, and clear guidance
- Not resistant to change
- Not going to figure it out entirely on their own
- Thrive with clear expectations, visible incentives, and scaffolding

**What converts need from you:**
- ✅ Structured training and clear examples
- ✅ Visible incentives tied to career progression
- ✅ Regular check-ins and feedback
- ✅ Internal success stories they can learn from

**What NOT to do:**
- ❌ Skip constraints (they'll revert to old ways under pressure)
- ❌ Assume they'll self-direct like catalysts
- ❌ Provide only inspiration without structure

**Key insight:** This is your largest group. They need the full CODER framework—especially Constraints and Expectations—to prevent reverting to "the old way."

### Anchors: The Skeptics and Resisters (15-20%)

**Who they are:**
- Skeptical about AI's value
- Scared of learning new ways of working
- Worried about job security
- Engage in quiet resistance (stalling while appearing to participate)

**The hard truth:** You can't wait for them to come around gradually. Competitive stakes are too high, pace of change too fast.

**What anchors need from you:**
- ✅ Crystal clear expectations and timelines
- ✅ Binary choices: get on board or get off the team
- ✅ Support if they choose to adapt
- ✅ Decisive action if they continue to resist

**What NOT to do:**
- ❌ Assume skeptics will eventually see the light with enough evidence and patience
- ❌ Let resistance slow down the entire organization
- ❌ Avoid hard conversations

**The compassionate approach:**

Offer support for those willing to adapt. But for those who refuse, help them find roles that better match their interests.

**This comes back to accountability:** Rewards and clear expectations make the choice binary and clear.

## How to Apply the CODER Framework

### Step 1: Identify Your Primary Barrier

Don't try to fix everything at once. Diagnose your biggest bottleneck:

**Political barriers:**
- Teams hesitant to use AI capabilities due to unclear boundaries
- Role confusion stopping projects

**Retrofitting:**
- Using AI to do existing work faster, not differently
- No breakthrough improvements or new capabilities

**Procurement:**
- Innovative people frustrated by timelines
- Teams working around official processes
- People won't even try due to friction

**Knowledge:**
- People speak the language but don't know how to change daily work
- Surface understanding without application

**Permission:**
- Lots of questions about what's allowed
- Little experimentation due to fear of crossing invisible lines

**Start with the barrier affecting the most people.**

### Step 2: Design Your Constraints

Pick 1-2 constraints that address your primary barrier:

**For political barriers:**
- Process constraint: "All cross-functional projects must define AI augmentation before kickoff"
- Review constraint: "Leadership reviews only work demonstrating AI usage"

**For retrofitting:**
- Time constraint: Monthly hackathon to rethink workflows from scratch
- Process constraint: "New initiatives require 'AI-native approach' doc before approval"

**For procurement:**
- Ownership solution: Create VP of AI to coordinate approvals
- Process constraint: Pre-approved AI tools list with fast-track procurement

**For knowledge:**
- Time constraint: Dedicated learning hours per week
- Resource constraint: Budget for courses tied to demonstrated application

**For permission:**
- Communication: Published guidelines on what's allowed/not allowed
- Segmentation: Different permission tiers for different groups

### Step 3: Assign Clear Ownership

**At the top:**
- CEO/Founder takes personal ownership of transformation
- Sets tone, removes obstacles, holds people accountable

**By function:**
- Each leader owns adoption for their domain
- Clear escalation path when they hit barriers

**Consider:**
- Dedicated VP of AI or transformation lead
- Coordinates across functions
- Bridges offensive (product teams) and defensive (legal, IT, finance) functions

### Step 4: Create 2-3 Directives Per Function

Make them:
- **Immediately actionable:** People can start today
- **Specific:** Exactly when and how to use AI
- **Integrated:** Into existing workflows, not add-ons

**Example set for Product team:**
1. "All user research must use AI synthesis before presenting findings"
2. "Every feature review must include AI-generated prototype"
3. "PRDs require AI-assisted competitive analysis"

### Step 5: Set Clear Expectations

For each function, define:
- What AI adoption looks like in practice
- Observable behaviors
- How to know if you're meeting the bar

**Make them:**
- Specific (not vague)
- Universal (everyone, no exceptions)
- Measurable (self-assessable)

### Step 6: Tie to Career Progression

Update:
- **Performance reviews:** Include AI adoption as evaluation criteria
- **Leveling guides:** Add AI competency to role requirements
- **Promotion criteria:** Make AI usage factor in advancement decisions

**Create progression framework like Zapier:**
- Different fluency levels (Aware → Exploratory → Proficient → Advanced → Expert)
- Expected levels by role
- Clear path for up-skilling

### Step 7: Create Dedicated Time and Space

**Run hackathons:**
- Could be 1 hour, 1 day, or 1 week
- Frees people from day-to-day work to think differently
- Helps even anchors see what it's like to be AI-native

**Zapier's approach:**
Full-company participation, regardless of technical capability. Goal: "Get hands on keyboards. Build something real to develop a sense of what is possible with AI. Learn together."

**Why it works:**
- Doing is more effective than directives and memos
- Creates camaraderie around AI
- People feel pulled to AI rather than pushed

### Step 8: Monitor and Iterate

**Track adoption by group:**
- Catalysts: Are you amplifying their successes?
- Converts: Are they getting support they need?
- Anchors: Have you made binary choices clear?

**Measure transformation:**
- Value capture: Efficiency gains
- Value creation: New capabilities, revenue from AI features
- Behavior change: Tool usage, workflow changes, career conversations

**Adjust the framework:**
- Are constraints working or creating unintended friction?
- Do directives need clarification?
- Are rewards motivating the right behaviors?

## Integration with Other Frameworks

### Prototype-First Development

**CODER enables prototype-first at org level:**

**Without CODER:**
- Individual PM tries to prototype instead of writing PRD
- Hits political barriers (designer/eng confusion)
- Faces procurement delays (can't expense v0/Bolt)
- Reverts to old way

**With CODER:**
- Constraint: "All features require prototype before PRD"
- Ownership: CPO drives adoption across product org
- Directive: "Use pre-approved prototyping tools (v0, Replit, Cursor)"
- Expectation: "Every PM must show working prototypes in reviews"
- Reward: Prototype quality in performance reviews

**See:** `/frameworks/ai-era-practices/prototype-first.md`

### Continuous Calibration (CC/CD)

**CODER ensures teams actually implement CC/CD:**

**Challenge:** CC/CD requires new workflows (evals, monitoring, versioning)

**CODER solution:**
- Directive: "All AI features must define evals before building"
- Expectation: "AI features launch at low agency, earn autonomy"
- Reward: Promotion criteria include "shipped calibrated AI feature"

**See:** `/frameworks/ai-era-practices/continuous-calibration.md`

### AI Evals (Aman Khan)

**CODER drives eval adoption:**

**Without CODER:** Teams understand evals are important but don't build them (takes time, unclear ownership)

**With CODER:**
- Constraint: "No AI feature ships without passing evals"
- Ownership: Each PM owns evals for their features
- Directive: "Build golden dataset before launch"
- Expectation: "All AI quality metrics tracked in prod"

**See:** `/frameworks/ai/ai-evals.md`

### Four Fits (Brian Balfour)

**CODER as the "Organization-Change Fit":**

Four Fits validates strategic alignment (market-product, product-channel, channel-model, model-market).

CODER validates **organization-change fit**: Is your organization structured to execute your AI strategy?

**If you have product-market fit with AI but lack organization-change fit:**
- Right product, wrong execution capability
- Competitors with better org alignment will win

### Teresa Torres' Continuous Discovery

**CODER enables continuous AI-assisted discovery:**

**Challenge:** Weekly customer conversations at scale

**CODER solution:**
- Directive: "All customer calls use AI transcription and synthesis"
- Expectation: "PMs conduct weekly interviews with AI note-taking"
- Constraint: Time dedicated to discovery, AI makes it scalable

**See:** `/frameworks/discovery/continuous-discovery.md`

## Common Mistakes

### ❌ Memo Without System

**Problem:** CEO writes inspiring memo about AI-first company, expects change to happen.

**Reality:** Without constraints, ownership, directives, expectations, and rewards—nothing changes.

**Better:** Memo + CODER framework implementation.

### ❌ Focusing Only on Catalysts

**Problem:** Assuming everyone will self-motivate like the 15% early adopters.

**Reality:** 70% need structure (converts) and 15% need clear accountability (anchors).

**Better:** Design for the willing majority, not just the enthusiastic few.

### ❌ Optimizing for Value Capture, Ignoring Value Creation

**Problem:** Celebrating 10% efficiency gains, missing opportunities for entirely new capabilities.

**Reality:** Competitors gain same efficiencies, you don't differentiate.

**Better:** Start with value capture (learn AI), move quickly to value creation (competitive advantage).

### ❌ No Dedicated Time and Space

**Problem:** Expecting people to learn AI and transform workflows while doing existing job at full capacity.

**Reality:** Under pressure, people revert to familiar approaches.

**Better:** Hackathons, dedicated learning time, constraints that force experimentation.

### ❌ Ignoring Procurement Barriers

**Problem:** Treating legal/IT/finance as pure blockers.

**Reality:** They have legitimate concerns, but also slow transformation when not aligned.

**Better:** Ownership at VP of AI level to coordinate across functions. Pre-approved tools. Clear risk frameworks.

### ❌ Vague Expectations

**Problem:** "Everyone should use AI more" without defining what that means by role.

**Reality:** People don't know where to start, what's expected, or how to measure success.

**Better:** Specific, universal, measurable expectations by function.

### ❌ No Career Consequences

**Problem:** AI adoption is "nice to have" but doesn't affect reviews, promotions, or compensation.

**Reality:** People prioritize what affects their career. Without consequences, adoption stays optional.

**Better:** Tie to performance reviews, leveling guides, promotion criteria.

## Key Takeaways

1. **Value creation > value capture** - Efficiency is table stakes, new capabilities are competitive advantage
2. **Five barriers block adoption** - Political, retrofitting, procurement, knowledge, permission
3. **CODER provides the system** - Constraints, Ownership, Directives, Expectations, Rewards
4. **Constraints are most important** - Make new behavior easier than old behavior
5. **Three types of adopters** - Catalysts (15%), Converts (70%), Anchors (15%)
6. **Design for converts** - They're the majority and need structure
7. **Create dedicated time** - Hackathons break the cycle, build momentum
8. **Tie to careers** - Adoption must affect performance reviews and progression
9. **Memos don't create change** - Systems create change
10. **There's still time** - Window for competitive advantage exists but is narrowing

## Further Learning

**Essential Resources:**

**Reforge:**
- "The CODER Framework: How To Become AI-Native" (Brian Balfour)
- AI Strategy course
- Product Strategy course

**Zapier:**
- Wade Foster's posts on AI adoption
- AI adoption handbook
- Company-wide hackathon approach

**Related Frameworks:**
- `/frameworks/ai-era-practices/prototype-first.md` - What PMs should do
- `/frameworks/ai-era-practices/continuous-calibration.md` - How to develop AI products
- `/frameworks/ai/ai-evals.md` - Testing AI quality
- `/thought-leaders/brian-balfour.md` - Growth strategy, focus wins

---

**Remember:** Organizational transformation doesn't happen by accident. You need a systematic approach that addresses multiple levels simultaneously: constraints that force change, ownership that drives it, directives that specify it, expectations that clarify it, and rewards that sustain it.

The window for competitive advantage through AI adoption is narrowing. Companies that implement CODER in 2025 will build sustainable advantages over those that continue to experiment without systematic change.

**The question isn't whether AI will transform how work gets done. The question is whether you'll lead that transformation or watch it happen around you.**
